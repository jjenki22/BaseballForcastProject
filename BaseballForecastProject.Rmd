---
title: "Baseball Forecasts"
author: "Joe Jenkins and Anthony Stachowski"
date: "11/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(fitdistrplus)
library(ggplot2)
library(fBasics)
library(fpp)
library(forecast)

# Importing data that was scraped from baseball-reference.com:
data <- read.csv("Data/BOS_NYY_2009_2019.csv", stringsAsFactors = FALSE)

# Creating an index that is a combination of the season (Year) and the game number (Rk):
data$Game_Year <- paste(data$Rk, data$Year, sep = "_")
data$yearGame <- as.integer(paste(as.character(data$Year), 
                                  ifelse(data$Rk < 10, 
                                         paste("00", as.character(data$Rk), sep = ""),
                                         ifelse(data$Rk >= 10 & data$Rk < 100, 
                                                paste("0", as.character(data$Rk), sep = ""),
                                                as.character(data$Rk))), sep = ""))
```

### Average 

```{r}
# Computing the average percentage of strikes thrown by game by assessing both NY and Bos:
avgData <- data %>% 
  group_by(yearGame, Year) %>% 
  summarise(mean_PerSK = mean(PerSK))

# Creating a time series from our data
# Also, separating data into testing set (2019 season) and training set (2009-2018 seasons)

# Testing set:
avgData2019 <- avgData %>% 
  dplyr::filter(Year == 2019)
# Testing set time series:
avgIndex2019 = ts(avgData2019$mean_PerSK,start=c(2019,1), frequency = 162)

# Training set:
avgData2009_2018 <- avgData %>% 
  dplyr::filter(Year < 2019)
# Training set time series:
avgIndex2009_2018 = ts(avgData2009_2018$mean_PerSK,start=c(2009,1), frequency = 162)
```
#### Time Plot 

```{r}
# Time plot of training set:
autoplot(avgIndex2009_2018) + xlab("Year Game Index") +
  ylab("Percent of Pitches That Are Strike") + ggtitle("Boston Red Sox and New York Yankees Percenatge of Pitches That Are Strikes 2009-2018") +
  theme_classic()

# There appears to be quite a bit of random fluctuation within our time series.
# There may be a slight trend upwards over our training set, but seems very minimal.
# No obvious seasonality or cycles based on visual assessment.
# Our average percentages vary between 55% and 75%.

# Time plot of testing set:
autoplot(avgIndex2019) + xlab("Year Game Index") +
  ylab("Percent of Pitches That Are Strike") + ggtitle("Boston Red Sox and New York Yankees Percenatge of Pitches That Are Strikes 2019") +
  theme_classic()

# Time plot of training set, season 2014 for closer view of individual year:
avgData2014 <- avgData %>% 
  dplyr::filter(Year == 2014)
avgIndex2014 = ts(avgData2014$mean_PerSK,start=c(2014,1), frequency = 162)
autoplot(avgIndex2014) + xlab("Year Game Index") +
  ylab("Percent of Pitches That Are Strike") + ggtitle("Boston Red Sox and New York Yankees Percenatge of Pitches That Are Strikes 2014") +
  theme_classic()
```

#### Check Distribution Aspects

```{r}
# Examining Basic Statistics of our training set and testing set:
basicStats(avgIndex2019)
basicStats(avgIndex2009_2018)

# Examining the nature of our distribution and checking for normality:

# Training Set:
descdist(as.numeric(avgIndex2009_2018), discrete = FALSE)
# Testing Set:
descdist(as.numeric(avgIndex2019), discrete = FALSE)

# Computing normal test using Jarque-Bera test, here we are examining if p-value is greater than alpha.
# We will compare the p-value against alpha values of 0.01 and 0.05.
# Training set:
fBasics::normalTest(avgIndex2009_2018, method = 'jb')
# Testing set:
fBasics::normalTest(avgIndex2019, method = "jb")

# Conclusion: our training set passes the J-B Test at an alpha of 0.01, but our testing set does not.

# Displaying normal plots for our data:
plot(fitdist(as.numeric(avgIndex2009_2018), "norm"))
plot(fitdist(as.numeric(avgIndex2019), "norm"))

# Conclusion: our training set appears to align with a normal distribution when examining normality plots. 
# Again the testing set does not, but this is not as problematic as we will be building the models using only the training set.

# Overall we conclude that our training set is normally distributed.


# Checking mean of our testing set to see whether it is different from zero:
t.test(avgIndex2009_2018)

# Resulting p-value is very small and therefore we can conclude that our mean value is different from zero.
```


### Forecasting Models:

#### Naive 

```{r}
# Uses most recent point as data for forecast values:
averageModelNaive <- naive(avgIndex2009_2018, h = 162)
plot(averageModelNaive)

# Assessing the accuracy of this model versus the actual data:
naive_acc <- accuracy(averageModelNaive, avgIndex2019)
naive_acc

# Creating list of error values for assessing all models:
naive_errors_test <- naive_acc[2,]

# Plotting portion of data for easier interpretation:
plot(avgIndex2009_2018, 
     xlim = c(2018.0, 2020.0),
     xlab = "Season and Game",
     ylab = "Percentage of Strikes Thrown",
     main = "Naive Forecasting on Segment of Data")
lines(naive(avgIndex2009_2018, h=162)$mean, col="red", lwd=2)
lines(avgIndex2019, col="blue")
```

#### SES

```{r}
# Using weighted averages of past values to create a flat forecast:
averageModelSES <- ses(avgIndex2009_2018, h = 162)
plot(averageModelSES)

# Assessing the accuracy of this model versus the actual data:
ses_acc <- accuracy(averageModelSES, avgIndex2019)
ses_acc

# Creating list of error values for assessing all models:
ses_errors_test <- ses_acc[2,]

# Plotting a portion of the data for easier interpretation:
plot(avgIndex2009_2018, 
     xlim = c(2018.0, 2020.0),
     xlab = "Season and Game",
     ylab = "Percentage of Strikes Thrown",
     main = "SES Forecasting on Segment of Data")
lines(ses(avgIndex2009_2018, h=162)$mean, col="green", lwd=2)
lines(avgIndex2019, col="blue")
```

#### ETS 

```{r}
# Using ETS model:
averageETS <- ets(avgIndex2009_2018)
summary(averageETS)
plot(averageETS)

# Output from model is ETS(A,N,N), this has additive error, no trend and no seasonality.
# The ETS plot seems to indicate that there may be a slight trend, but this was not strong enough that the model felt the need to account for the trend.

# Assessing the accuracy of the ETS Model:
ETSForecast <- forecast(averageETS, h = 162)
plot(ETSForecast)
ETS_acc <- accuracy(ETSForecast, avgData2019$mean_PerSK)
ETS_acc

# Creating list of error values for assessing all models:
ets_errors_test <- ETS_acc[2,]

# Plotting a portion of the data for easier interpretation:
plot(avgIndex2009_2018, 
     xlim = c(2018.0, 2020.0),
     xlab = "Season and Game",
     ylab = "Percentage of Strikes Thrown",
     main = "ETS(A,N,N) Forecasting on Segment of Data")
lines(ETSForecast$mean, col="cyan", lwd=2)
lines(avgIndex2019, col="blue")
```
#### Pre-Processing for ARIMA:
#### Box-Cox Transformation

```{r}
# We will assess the Box Cox lambda to see if our data needs to be transformed:
BoxCox.lambda(avgIndex2009_2018)

# This is indicating a lambda greater than 1 and therefore we will not transform our data.
```


#### ACF

```{r}
# Examine the data visually to see if there are concerns around our data not being stationary:
ggAcf(avgIndex2009_2018) + ggtitle("ACF Plot for 2009-2018 Seasons")
ggPacf(avgIndex2009_2018)+ ggtitle("PACF Plot for 2009-2018 Seasons")

# We will conduct a Dickey-Fuller test to confirm the visual assessment:
adf.test(avgIndex2009_2018)

# The Dickey-Fuller test outputs a p-value smaller 0.01, which would indicate our data is stationary.
# However, we will test using ndiffs and nsdiffs to see if there might be an indication of adjustments that should be made for differencing:

ndiffs(avgIndex2009_2018)
# Suggests that 1 difference should be done to make data more stationary.
nsdiffs(avgIndex2009_2018)
# Suggests that no seasonal differencing is needed.

# Examine visual details once one differencing is done:
tsdisplay(diff(avgIndex2009_2018))
# Data now looks much more stationary, although there ADF Test did not indicate a strong need to difference our data.
```

#### Ljung-Box Test:

```{r}
log(length(avgIndex2009_2018)) # Based on our data, we should really only check up to around 7.4

# Lag 1
Box.test(avgIndex2009_2018,lag=1,type='Ljung')
# Lag 2
Box.test(avgIndex2009_2018,lag=2,type='Ljung')
# Lag 3
Box.test(avgIndex2009_2018,lag=3,type='Ljung') 
# Lag 5
Box.test(avgIndex2009_2018,lag=5,type='Ljung')
# Lag 7
Box.test(avgIndex2009_2018,lag=7,type='Ljung')
# Lag 9
Box.test(avgIndex2009_2018,lag=9,type='Ljung')

# Based on these results it looks like we have serial correlation occurring in our data as the p-values are all very small
```

#### ARIMA 

```{r}
# We will now examine an ARIMA forecasting model for our data set using auto.arima.
# Based on the above pre-processing information and testing it looks like an ARIMA model will include a differencing of 1.
# The Ljung-Test has also shown that we may have serial correlation occurring and this may also impact the ARIMA model that is chosen. Examining the ACF and PACF plots it is likely that there is an autoregression component that may be output by the model.
# As indicated in our class notes, the ARIMA model includes three components:
# p = order of the autoregression component
# d = degree of differencing involved
# q = order of moving average component

ARIMA_model1 = auto.arima(avgIndex2009_2018)
# Output is a ARIMA(5,1,1) model
summary(ARIMA_model1)
tsdisplay(ARIMA_model1$residuals) # Residuals look pretty close to white noise
Box.test(ARIMA_model1$residuals, lag = 7, type = 'Ljung') # Residuals are white noise

# Assessing the accuracy of the ETS Model:
ARIMAForecast <- forecast(ARIMA_model1, h = 162)
plot(ARIMAForecast)
ARIMA_acc <- accuracy(ARIMAForecast, avgData2019$mean_PerSK)
ARIMA_acc

# Creating list of error values for assessing all models:
arima_errors_test <- ARIMA_acc[2,]

# Plotting a portion of the data for easier interpretation:
plot(avgIndex2009_2018, 
     xlim = c(2018.0, 2020.0),
     xlab = "Season and Game",
     ylab = "Percentage of Strikes Thrown",
     main = "ARIMA(5,1,1) Forecasting on Segment of Data")
lines(ARIMAForecast$mean, col="orange", lwd=2)
lines(avgIndex2019, col="blue")
```
#### Examining Errors and AICc where appropriate:

```{r}
print("Naive Forecast Errors")
naive_errors_test
print("SES Forecast Errors")
ses_errors_test
print("ETS Forecast Errors")
ets_errors_test
print("ARIMA Forecast Errors")
arima_errors_test

# Based on analyzing the errors from the four methods used, SES performs the best for our data.

print("ETS AICc")
averageETS$aicc
print("ARIMA AICc")
ARIMA_model1$aicc

```

### Boston 

```{r}
Bos2019 <- data %>% 
  dplyr::filter(Team == "BOS" & Year == 2019)
BosIndex2019 = ts(Bos2019$PerSK,start=c(2019,1), frequency = 162)
Bos2009_2018 <- data %>% 
  dplyr::filter(Team == "BOS" & Year < 2019)
BosIndex2009_2018 = ts(Bos2009_2018$PerSK,start=c(2009,1), frequency = 162)
```

#### Check Distribution 

```{r}
descdist(as.numeric(BosIndex2009_2018), discrete = FALSE)
descdist(as.numeric(BosIndex2019), discrete = FALSE)
fBasics::normalTest(BosIndex2009_2018, method = 'jb')
basicStats(BosIndex2019)
basicStats(BosIndex2009_2018)
fBasics::normalTest(BosIndex2019, method = "jb")  
basicStats(as.numeric(BosIndex2009_2018))
plot(fitdist(as.numeric(BosIndex2009_2018), "norm"))
plot(fitdist(as.numeric(BosIndex2019), "norm"))
```

#### Time Plot 

```{r}
autoplot(BosIndex2009_2018) + xlab("Year Game Index") +
  ylab("Percent of Pitches That Are Strike") + ggtitle("Boston Red Sox Percenatge of Pitches That Are Strikes 2009-2018") +
  theme_classic()
autoplot(BosIndex2019) + xlab("Year Game Index") +
  ylab("Percent of Pitches That Are Strike") + ggtitle("Boston Red Sox Percenatge of Pitches That Are Strikes 2019") +
  theme_classic()
Bos2014 <- data %>% 
  dplyr::filter(Team == "BOS" & Year == 2014)
BosIndex2014 = ts(Bos2019$PerSK,start=c(2014,1), frequency = 162)
autoplot(BosIndex2014) + xlab("Year Game Index") +
  ylab("Percent of Pitches That Are Strike") + ggtitle("Boston Red Sox Percenatge of Pitches That Are Strikes 2014") +
  theme_classic()
```

#### Naive

```{r}
BosNaive <- naive(BosIndex2009_2018, h = 162)
accuracy(BosNaive, BosIndex2019)
```

#### SES

```{r}
BosModelSES <- ses(BosIndex2009_2018, h = 162)
accuracy(BosModelSES, BosIndex2019)
```

#### ETS

```{r}
BosETS <- ets(Bos2009_2018$PerSK)
summary(BosETS)
BosETSForcast <- forecast(BosETS, h = 162)
accuracy(BosETSForcast, Bos2019$PerSK)
```

#### ACF

```{r}
adf.test(BosIndex2009_2018)
ggAcf(BosIndex2009_2018)
Pacf(BosIndex2009_2018)
tsdisplay(diff(BosIndex2009_2018))
ndiffs(BosIndex2009_2018)
nsdiffs(BosIndex2009_2018)
```

#### Box Test 

```{r}
Box.test(BosIndex2009_2018,lag=10,type='Ljung') 
Box.test(BosIndex2009_2018,lag=5,type='Ljung')
Box.test(BosIndex2009_2018,lag=20,type='Ljung')
Box.test(BosIndex2009_2018,lag=7,type='Ljung')
Box.test(BosIndex2009_2018,lag=162,type='Ljung')
```

#### T Test

```{r}
t.test(BosIndex2009_2018)
```

#### Arima 

```{r}
auto.arima(BosIndex2009_2018)
### Arima 3, 1, 1
BosArima3_1_1 <-  Arima(BosIndex2009_2018, order= c(3,1,1))
summary(BosArima3_1_1)

### Arima 3, 0, 1
BosArima3_0_1 <-  Arima(BosIndex2009_2018, order= c(3,0,1))
summary(BosArima3_0_1)

### Arima 3, 1, 0
BosArima3_1_0 <-  Arima(BosIndex2009_2018, order= c(3,1, 0))
summary(BosArima3_1_0)

### Arima 3, 2, 2
BosArima3_2_2 <-  Arima(BosIndex2009_2018, order= c(3,2,2))
summary(BosArima3_2_2)

### Arima 3,2,1 
BosArima3_2_1 <-  Arima(BosIndex2009_2018, order= c(3,2,1))
summary(BosArima3_2_1)

### Arima 3,1,2 
BosArima3_1_2 <-  Arima(BosIndex2009_2018, order= c(3,1,2))
summary(BosArima3_1_2)

### Arima 3, 1, 1
BosArima3_1_1 <-  Arima(BosIndex2009_2018, order= c(3,1,1))
summary(BosArima3_1_1)

### Arima 3, 0, 1
BosArima3_0_1 <-  Arima(BosIndex2009_2018, order= c(3,0,1))
summary(BosArima3_0_1)

### Arima 3, 1, 0
BosArima3_1_0 <-  Arima(BosIndex2009_2018, order= c(3,1, 0))
summary(BosArima3_1_0)

### Arima 3, 2, 2
BosArima3_2_2 <-  Arima(BosIndex2009_2018, order= c(3,2,2))
summary(BosArima3_2_2)

### Arima 3,2,1 
BosArima3_2_1 <-  Arima(BosIndex2009_2018, order= c(3,2,1))
summary(BosArima3_2_1)

### Arima 3,1,2 
BosArima3_1_2 <-  Arima(BosIndex2009_2018, order= c(3,1,2))
summary(BosArima3_1_2)

### Arima 4, 1, 1
BosArima4_1_1 <-  Arima(BosIndex2009_2018, order= c(4,1,1))
summary(BosArima4_1_1)

### Arima 4, 0, 1
BosArima4_0_1 <-  Arima(BosIndex2009_2018, order= c(4,0,1))
summary(BosArima4_0_1)

### Arima 4, 1, 0
BosArima4_1_0 <-  Arima(BosIndex2009_2018, order= c(4,1, 0))
summary(BosArima4_1_0)

### Arima 4, 2, 2
BosArima4_2_2 <-  Arima(BosIndex2009_2018, order= c(4,2,2))
summary(BosArima4_2_2)

### Arima 4,2,1 
BosArima4_2_1 <-  Arima(BosIndex2009_2018, order= c(4,2,1))
summary(BosArima4_2_1)

### Arima 4,1,2 
BosArima4_1_2 <-  Arima(BosIndex2009_2018, order= c(4,1,2))
summary(BosArima4_1_2)

### Arima 5, 1, 1
BosArima5_1_1 <-  Arima(BosIndex2009_2018, order= c(5,1,1))
summary(BosArima5_1_1)

### Arima 5, 0, 1
BosArima5_0_1 <-  Arima(BosIndex2009_2018, order= c(5,0,1))
summary(BosArima5_0_1)

### Arima 5, 1, 0
BosArima5_1_0 <-  Arima(BosIndex2009_2018, order= c(5,1, 0))
summary(BosArima5_1_0)

### Arima 5, 2, 2
BosArima5_2_2 <-  Arima(BosIndex2009_2018, order= c(5,2,2))
summary(BosArima5_2_2)

### Arima 5,2,1 
BosArima5_2_1 <-  Arima(BosIndex2009_2018, order= c(5,2,1))
summary(BosArima5_2_1)

### Arima 5,1,2 
BosArima5_1_2 <-  Arima(BosIndex2009_2018, order= c(5,1,2))
summary(BosArima5_1_2)
```

### New York 

```{r}
Nyy2019 <- data %>% 
  dplyr::filter(Team == "NYY" & Year == 2019)
NyyIndex2019 = ts(Nyy2019$PerSK,start=c(2019,1), frequency = 162)
Nyy2009_2018 <- data %>% 
  dplyr::filter(Team == "NYY" & Year < 2019)
NyyIndex2009_2018 = ts(Nyy2009_2018$PerSK,start=c(2009,1), frequency = 162)
```

#### Check Distribution

```{r}
descdist(as.numeric(NyyIndex2009_2018), discrete = FALSE)
descdist(as.numeric(NyyIndex2019), discrete = FALSE)
fBasics::normalTest(NyyIndex2009_2018, method = 'jb')
basicStats(NyyIndex2019)
basicStats(NyyIndex2009_2018)
fBasics::normalTest(NyyIndex2019, method = "jb")  
basicStats(as.numeric(NyyIndex2009_2018))
plot(fitdist(as.numeric(NyyIndex2009_2018), "norm"))
plot(fitdist(as.numeric(NyyIndex2019), "norm"))
```

#### Time Plot

```{r}
autoplot(NyyIndex2009_2018) + xlab("Year Game Index") +
  ylab("Percent of Pitches That Are Strike") + ggtitle("New York Yankees Percenatge of Pitches That Are Strikes 2009-2018") +
  theme_classic()
autoplot(NyyIndex2019) + xlab("Year Game Index") +
  ylab("Percent of Pitches That Are Strike") + ggtitle("New York Yankees Percenatge of Pitches That Are Strikes 2019") +
  theme_classic()
Nyy2014 <- data %>% 
  dplyr::filter(Team == "NYY" & Year == 2014)
NyyIndex2014 = ts(Nyy2014$PerSK,start=c(2014,1), frequency = 162)
autoplot(NyyIndex2014) + xlab("Year Game Index") +
  ylab("Percent of Pitches That Are Strike") + ggtitle("New York Yankees Percenatge of Pitches That Are Strikes 2014") +
  theme_classic()
```

#### Naive 

```{r}
NyyNaive <- naive(NyyIndex2009_2018, h = 162)
accuracy(NyyNaive, NyyIndex2019)
```

#### SES

```{r}
NyyModelSES <- ses(NyyIndex2009_2018, h = 162)
accuracy(NyyModelSES, NyyIndex2019)
```

#### ETS 

```{r}
NyyETS <- ets(Nyy2009_2018$PerSK)
summary(NyyETS)
NyyETSForcast <- forecast(NyyETS, h = 162)
accuracy(NyyETSForcast, Nyy2019$PerSK)
```

#### ACF

```{r}
adf.test(NyyIndex2009_2018)
ggAcf(NyyIndex2009_2018)
Pacf(NyyIndex2009_2018)
tsdisplay(diff(NyyIndex2009_2018))
ndiffs(NyyIndex2009_2018)
nsdiffs(NyyIndex2009_2018)
```

#### Box Test 

```{r}
Box.test(NyyIndex2009_2018,lag=10,type='Ljung') 
Box.test(NyyIndex2009_2018,lag=5,type='Ljung')
Box.test(NyyIndex2009_2018,lag=20,type='Ljung')
Box.test(NyyIndex2009_2018,lag=7,type='Ljung')
Box.test(NyyIndex2009_2018,lag=162,type='Ljung')
```

#### T Test

```{r}
t.test(NyyIndex2009_2018)
```

#### Arima 

```{r}
## New York
auto.arima(NyyIndex2009_2018)

### Arima 0, 1, 1
NyyArima0_1_1 <-  Arima(NyyIndex2009_2018, order= c(0,1,1))
summary(NyyArima0_1_1)

### Arima 0, 1, 2
NyyArima0_1_2 <-  Arima(NyyIndex2009_2018, order= c(0,1,2))
summary(NyyArima0_1_2)

### Arima 0, 1, 3
NyyArima0_1_3 <-  Arima(NyyIndex2009_2018, order= c(0,1,3))
summary(NyyArima0_1_3)

### Arima 0, 0, 2
NyyArima0_0_2 <-  Arima(NyyIndex2009_2018, order= c(0,0,2))
summary(NyyArima0_0_2)

### Arima 0, 2, 3
NyyArima0_2_3 <-  Arima(NyyIndex2009_2018, order= c(0,2,3))
summary(NyyArima0_2_3)

### Arima 1,1,1 
NyyArima1_1_1 <-  Arima(NyyIndex2009_2018, order= c(1,1,1))
summary(NyyArima1_1_1)

### Arima 1,1,2
NyyArima1_1_2 <-  Arima(NyyIndex2009_2018, order= c(1,1,2))
summary(NyyArima1_1_2)

### Arima 1,2,1
NyyArima1_2_1 <-  Arima(NyyIndex2009_2018, order= c(1,2,1))
summary(NyyArima1_2_1)
```